<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  <meta name="description"
        content="KoopMotion: Learning Almost Divergence Free Koopman Flow Fields for Motion Planning">
  <meta name="keywords" content="KoopMotion, koopman operator theory">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  <title>KoopMotion: </title>

  <link href="https://fonts.googleapis.com/css?family=Google+Sans|Noto+Sans|Castoro"
        rel="stylesheet">

  <link rel="stylesheet" href="./static/css/bulma.min.css">
  <link rel="stylesheet" href="./static/css/bulma-carousel.min.css">
  <link rel="stylesheet" href="./static/css/bulma-slider.min.css">
  <link rel="stylesheet" href="./static/css/fontawesome.all.min.css">
  <link rel="stylesheet"s
        href="https://cdn.jsdelivr.net/gh/jpswalsh/academicons@1/css/academicons.min.css">
  <link rel="stylesheet" href="./static/css/index.css">
  <link rel="icon" href="./static/images/penn.png">

  <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.5.1/jquery.min.js"></script>
  <script defer src="./static/js/fontawesome.all.min.js"></script>
  <script src="./static/js/bulma-carousel.min.js"></script>
  <script src="./static/js/bulma-slider.min.js"></script>
  <script src="./static/js/index.js"></script>
</head>
<body>

<nav class="navbar" role="navigation" aria-label="main navigation">
  <div class="navbar-brand">
    <a role="button" class="navbar-burger" aria-label="menu" aria-expanded="false">
      <span aria-hidden="true"></span>
      <span aria-hidden="true"></span>
      <span aria-hidden="true"></span>
    </a>
  </div>
  <div class="navbar-menu">
    <div class="navbar-start" style="flex-grow: 1; justify-content: center;">
      <a class="navbar-item" href="https://alicekl.github.io/">
      <span class="icon">
          <i class="fas fa-home"></i>
      </span>
      </a>

      <div class="navbar-item has-dropdown is-hoverable">
        <a class="navbar-link">
          More Research
        </a>
        <div class="navbar-dropdown">
          <a class="navbar-item" href="https://alicekl.github.io/project/enkode/">
            EnKode
          </a>
          <a class="navbar-item" href="https://alicekl.github.io/project/koopman/">
            FourierKoopman
          </a>
        </div>
      </div>
    </div>

  </div>
</nav>


<section class="hero">
  <div class="hero-body">
    <div class="container is-max-desktop">
      <div class="columns is-centered">
        <div class="column has-text-centered">
          <h1 class="title is-1 publication-title">KoopMotion: Learning Almost Divergence Free Koopman Flow Fields for Motion Planning</h1>
          <div class="is-size-5 publication-authors">
            <span class="author-block">
              <a href="https://alicekl.github.io/">Alice Kate Li</a>,</span>
            <span class="author-block">
              <a href="https://scthales.github.io/">Thales C. Silva </a>,</span>
            <span class="author-block">
              <a href="https://vmedwards.github.io/">Victoria Edwards</a>,
            </span>
            <span class="author-block">
              <a href="https://www.kumarrobotics.org/">Vijay Kumar</a>,
            </span>
            <span class="author-block">
              <a href="https://mhsieh.seas.upenn.edu/">M. Ani Hsieh</a>
            </span>
          </div>

          <div class="is-size-5 publication-authors">
            <span class="author-block">GRASP Lab, University of Pennsylvania,</span>
          </div>
          
          <h2 class="is-size-4"><strong>Conference on Robot Learning (CoRL 2025)</strong></h2>

          <div class="column has-text-centered">
            <div class="publication-links">
              <!-- PDF Link. -->
              <span class="link-block">
                <a href="https://arxiv.org/abs/2509.09074"
                   class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                      <i class="fas fa-file-pdf"></i>
                  </span>
                  <span>Paper</span>
                </a>
              </span>
              
              <!-- Code Link. -->
              <span class="link-block">
                <a href="https://github.com/alicekl/koopmotion"
                   class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                      <i class="fab fa-github"></i>
                  </span>
                  <span>Code</span>
                  </a>
              </span>
            </div>

          </div>
        </div>
      </div>
    </div>
  </div>
</section>

<section class="hero teaser">
  <div class="container is-max-desktop">
    <div class="hero-body">
      <video id="teaser" autoplay muted loop playsinline height="100%">
        <source src="./static/videos/project.mp4"
                type="video/mp4">
      </video>
      <h2 class="subtitle has-text-centered">
        <span class="dnerf">KoopMotion</span> learns dynamical systems from demonstrations for motion planning.
      </h2>
    </div>
  </div>
</section>



<section class="section">
  <div class="container is-max-desktop">
    <!-- Abstract. -->
    <div class="columns is-centered has-text-centered">
      <div class="column is-four-fifths">
        <h2 class="title is-3">Abstract</h2>
        <div class="content has-text-justified">
          <p>
            In this work, we propose a novel flow field-based motion planning method that drives a robot from any initial state to a desired reference trajectory such that it converges to the trajectory's end point. 


          </p>
          <p>
            Despite demonstrated efficacy in using Koopman operator theory for modeling dynamical systems, Koopman does not inherently enforce convergence to desired trajectories nor to specified goals&mdash;a requirement when learning from demonstrations (LfD). 
We present KoopMotion which represents motion flow fields as dynamical systems, parameterized by Koopman Operators to mimic desired trajectories, and leverages the divergence properties of the learnt flow fields to obtain smooth motion fields that converge to a desired reference trajectory when a robot is placed away from the desired trajectory, and tracks the trajectory until the end point.
          </p>
          <p>
            To demonstrate the effectiveness of our approach, we show evaluations of KoopMotion on the LASA human handwriting dataset and a 3D manipulator end-effector trajectory dataset, including spectral analysis.
We also perform experiments on a physical robot, verifying KoopMotion on a miniature autonomous surface vehicle operating in a non-static fluid flow environment.
Our approach is highly sample efficient in both space and time, requiring only <strong>3%</strong> of the LASA dataset to generate dense motion plans.
Additionally, KoopMotion provides a significant improvement over baselines when comparing metrics that measure spatial and temporal dynamics modeling efficacy. 
          </p>
        </div>
      </div>
    </div>
    <!--/ Abstract. -->



<section class="section">
  <div class="container is-max-desktop">

    <div class="columns is-centered">

      <!-- LfD. -->
      <div class="column">
        <div class="content">
          <h3 class="title is-4">Learning from Demonstrations (LfD)</h3>
          <p>
            Using <span class="dnerf">KoopMotion</span>, we learn motion policies <strong>(black)</strong> from demonstrations <span style="color: red; font-weight: bold;"> (red)</span>. Using a Koopman operator theoretic approach, we are able to learn a smooth underlying dynamical system that captures the <strong>spatial</strong> and <strong>temporal</strong> structure of the demonstrations. 
          </p>
          <video id="dollyzoom" autoplay controls muted loop playsinline height="100%">
            <source src="./static/videos/khamesh_demo_to_dynamical_system.mp4"
                    type="video/mp4">
          </video>
        </div>
      </div>
      <!--/ LfD. -->

      <!-- Attractor. -->
      <div class="column">
        <h3 class="title is-4">Novel KoopMotion Losses</h3>
        <div class="columns is-centered">
          <div class="column content">
            <p>
              We introduce additional novel loss terms to our optimize over, so that the surrounding vector field <span style="color: gray; font-weight: bold;"> (gray)</span> guides the system (a robot) toward the desired demonstration when away from the <span style="color: green; font-weight: bold;"> (green)</span> initial conditions along the <span style="color: blue; font-weight: bold;"> (blue)</span> trajectories, and to stop at the demonstration end-point.
            </p>
            <video id="matting-video" autoplay controls muted loop playsinline height="100%">
              <source src="./static/videos/output_khamesh_experiment2.mp4"
                      type="video/mp4">
            </video>
          </div>

        </div>
      </div>
    </div>
    <!--/ Attractor. -->

<section class="section">
  <h3 class="title is-4">Additional examples of learning from demonstrations from the <a
              href="https://github.com/justagist/pyLasaDataset"> LASA Dataset </a> </h3>
  <div class="container is-max-desktop">
    <div class="columns is-multiline is-centered">
      

      <!-- LfD -->
      <div class="column is-one-third">
        <div class="content is-centered">
          <p>
           SharpC
          </p>
          <video autoplay controls muted loop playsinline width="100%">
            <source src="./static/videos/output_sharpc_experiment2.mp4" type="video/mp4">
          </video>
        </div>
      </div>
      <!--/ LfD -->

      <!-- Attractor 1 -->
      <div class="column is-one-third">
        <div class="content is-centered">
          
          <p>
           Leaf2
          </p>
          <video autoplay controls muted loop playsinline width="100%">
            <source src="./static/videos/output_leaf2_experiment2.mp4" type="video/mp4">
          </video>
        </div>
      </div>
      <!--/ Attractor 1 -->

      <!-- Attractor 2 (duplicate for now) -->
      <div class="column is-one-third">
        <div class="content is-centered">
          
          <p>
            Snake 
          </p>
          <video autoplay controls muted loop playsinline width="100%">
            <source src="./static/videos/output_snake_experiment2.mp4" type="video/mp4">
          </video>
        </div>
      </div>
      
       <!-- Attractor 2 (duplicate for now) -->
      <div class="column is-one-third">
        <div class="content is-centered">
          
          <p>
            S Shape
          </p> 
          <video autoplay controls muted loop playsinline width="100%">
            <source src="./static/videos/output_s_experiment3.mp4" type="video/mp4">
          </video>
        </div>
      </div>
      
      
       <!-- Attractor 2 (duplicate for now) -->
      <div class="column is-one-third">
        <div class="content is-centered">
          
          <p>
            BendedLine
          </p> 
          <video autoplay controls muted loop playsinline width="100%">
            <source src="./static/videos/output_bended_line_experiment2.mp4" type="video/mp4">
          </video>
        </div>
      </div>
      
      <!-- Attractor 2 (duplicate for now) -->
      <div class="column is-one-third">
        <div class="content is-centered">
          
          <p>
            J2
          </p> 
          <video autoplay controls muted loop playsinline width="100%">
            <source src="./static/videos/output_j2_experiment2.mp4" type="video/mp4">
          </video>
        </div>
      </div>

    </div>
  </div>
</section>


<section class="section">
  <div class="container is-max-desktop">

    <div class="column is-full has-text-centered">

      <!-- LfD. -->
      <div class="columns is-centered">
        <div class="content">
          <h3 class="title is-4">Learning flow fields with more than one pattern</h3>
          <p>
            We can also learn flow fields where demonstrations start from different groups of initial conditions, and exhibit different speeds. 
          </p>
          <video id="dollyzoom" autoplay controls muted loop playsinline width="50%">
            <source src="./static/videos/output_mm4_experiment2.mp4"
                    type="video/mp4">
          </video>
        </div>
      </div>
      <!--/ LfD. -->
    </div>
  </div>
</section>


<section class="section">
  <h3 class="title is-4">Convergence from additional points (Circular and Linear) </h3>
  <div class="container is-max-desktop">
    <div class="columns is-multiline is-centered">
      

      <!-- LfD -->
      <div class="column is-one-half">
        <div class="content is-centered">
          <p>
           G Shape convergence from original domain 
          </p>
          <video autoplay controls muted loop playsinline width="100%">
            <source src="./static/videos/output_lasa_g.mp4" type="video/mp4">
          </video>
        </div>
      </div>
      <!--/ LfD -->

      <!-- Attractor 1 -->
      <div class="column is-one-half">
        <div class="content is-centered">
          
          <p>
           G Shape cnvergence from increased domain 
          </p>
          <video autoplay controls muted loop playsinline width="100%">
            <source src="./static/videos/output_lasa_g_from_afar.mp4" type="video/mp4">
          </video>
        </div>
      </div>
      <!--/ Attractor 1 -->

      
    </div>
  </div>
</section>



<section class="section">
  <h3 class="title is-4"> </h3>
  <div class="container is-max-desktop">
    <div class="columns is-multiline is-centered">

<!-- LfD -->
      <div class="column is-one-third">
        <div class="content is-centered">
          <p>
           N Shape convergence from original domain 
          </p>
          <video autoplay controls muted loop playsinline width="100%">
            <source src="./static/videos/output_n.mp4" type="video/mp4">
          </video>
        </div>
      </div>
      <!--/ LfD -->


      <div class="column is-one-third">
        <div class="content is-centered">
          <p>
           N Shape convergence from increased domain 
          </p>
          <video autoplay controls muted loop playsinline width="100%">
            <source src="./static/videos/output_n_from_afar_medium.mp4" type="video/mp4">
          </video>
        </div>
      </div>
      <!-- Attractor 1 -->
      <div class="column is-one-third">
        <div class="content is-centered">
          
          <p>
           N Shape convergence from an even larger domain 
          </p>
          <video autoplay controls muted loop playsinline width="100%">
            <source src="./static/videos/output_n_from_afar_high.mp4" type="video/mp4">
          </video>
        </div>
      </div>
      <!--/ Attractor 1 -->


    </div>
  </div>
</section>


<section class="section">
  <h3 class="title is-4">Presented at CORL 2025</h3>
  <div class="container is-max-desktop">
    <div class="columns is-multiline is-centered">
      

      <!-- LfD -->
      <div class="column is-one-forth">
        <div class="column is-full has-text-centered">
          <video autoplay controls muted loop playsinline width="100%">
            <source src="./static/videos/output_sharpc_experiment2.mp4" type="video/mp4">
          </video>
        </div>
      </div>
      <!--/ LfD -->

      <!-- Attractor 1 -->
      <div class="column is-one-forth">
        <div class="column is-full has-text-centered">
          <video autoplay controls muted loop playsinline width="100%">
            <source src="./static/videos/output_bended_line_experiment2.mp4" type="video/mp4">
          </video>
        </div>
      </div>
      <!--/ Attractor 1 -->

      <!-- Attractor 2 (duplicate for now) -->
      <div class="column is-one-forth">
        <div class="column is-full has-text-centered">
          <video autoplay controls muted loop playsinline width="100%">
            <source src="./static/videos/output_r_experiment2.mp4" type="video/mp4">
          </video>
        </div>
      </div>
      
       <!-- Attractor 2 (duplicate for now) -->
      <div class="column is-one-forth">
        <div class="column is-full has-text-centered">
          <video autoplay controls muted loop playsinline width="100%">
            <source src="./static/videos/output_l_experiment2.mp4" type="video/mp4">
          </video>
        </div>
      </div>
      
      
      
    </div>
  </div>
</section>
    

<section class="section" id="BibTeX">
  <div class="container is-max-desktop content">
    <h2 class="title">BibTeX</h2>
    <pre><code>@article{li2025koopmotion,
  author    = {Alice Kate Li, Thales C. Silva, Victoria Edwards, Vijay Kumar, and M. Ani Hsieh},
  title     = {KoopMotion: Learning Almost Divergence Free Koopman Flow Fields for Motion Planning},
  journal   = {Conference on Robot Learning (CoRL)},
  year      = {2025},
  url={https://arxiv.org/abs/2509.09074}, 
}</code></pre>
  </div>
</section>


<footer class="footer">
  <div class="container">
    <div class="content has-text-centered">
      <a class="icon-link"
         href="./static/videos/nerfies_paper.pdf">
        <i class="fas fa-file-pdf"></i>
      </a>
      <a class="icon-link" href="https://github.com/keunhong" class="external-link" disabled>
        <i class="fab fa-github"></i>
      </a>
    </div>
    <div class="columns is-centered">
      <div class="column is-8">
        <div class="content">
          <p>
            This website is licensed under a <a rel="license"
                                                href="http://creativecommons.org/licenses/by-sa/4.0/">Creative
            Commons Attribution-ShareAlike 4.0 International License</a>.
          </p>
          <p>
            This website was modified from <a href="https://nerfies.github.io/" >Nerfies.</a> From their website:
            You are free to borrow the <a
              href="https://github.com/nerfies/nerfies.github.io">source code</a> of this website,
            we just ask that you link back to this page in the footer.
          </p>
        </div>
      </div>
    </div>
  </div>
</footer>

</body>
</html>
